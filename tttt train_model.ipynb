{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'set_session' from 'keras.backend' (/home/ali/anaconda3/envs/env/lib/python3.8/site-packages/keras/backend.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# from keras.backend.tensorflow_backend import set_session\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_session\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSVLogger\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'set_session' from 'keras.backend' (/home/ali/anaconda3/envs/env/lib/python3.8/site-packages/keras/backend.py)"
     ]
    }
   ],
   "source": [
    "#Import library\n",
    "\n",
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.layers import (Input, Activation, Conv3D, Dense, Dropout, Flatten, \n",
    "                          MaxPooling3D, BatchNormalization, AveragePooling3D, \n",
    "                          Reshape, Lambda, GlobalAveragePooling3D, Concatenate,\n",
    "                          ReLU, Add)\n",
    "\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend import set_session\n",
    "\n",
    "from keras.callbacks import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, result_dir):\n",
    "    '''\n",
    "    Plots the accuracy and loss graphs of train and val and saves them.\n",
    "    '''\n",
    "\n",
    "    plt.plot(history.history['accuracy'], marker='.')\n",
    "    plt.plot(history.history['val_accuracy'], marker='.')\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend(['accuracy', 'val_accuracy'], loc='lower right')\n",
    "    plt.savefig(os.path.join(result_dir, 'model_accuracy.png'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'], marker='.')\n",
    "    plt.plot(history.history['val_loss'], marker='.')\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid()\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "    plt.savefig(os.path.join(result_dir, 'model_loss.png'))\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Videoto3D:\n",
    "\n",
    "    def __init__(self, width, height, depth):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.depth = depth\n",
    "\n",
    "    def video3d(self, filename):\n",
    "        \n",
    "        frames = []\n",
    "        index = len(os.listdir(filename)) // self.depth\n",
    "        images = os.listdir(filename)[::index]\n",
    "        images = images[0:25]\n",
    "        images.sort()\n",
    "\n",
    "        for img in images:\n",
    "\n",
    "            img_path = os.path.join(filename, img)\n",
    "            frame = cv2.imread(img_path)\n",
    "            frame = cv2.resize(frame, (self.height, self.width))\n",
    "            frames.append(frame)\n",
    "\n",
    "        return np.array(frames) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(video_dir, result_dir, nb_classes = 101, img_size = 224, frames = 25):\n",
    "    '''\n",
    "    Preprocess the videos into X and Y and saves in npz format and \n",
    "    computes input shape\n",
    "    '''\n",
    "\n",
    "    img_rows, img_cols  = img_size, img_size\n",
    "\n",
    "    channel = 3\n",
    "\n",
    "    files = os.listdir(video_dir)\n",
    "    files.sort()\n",
    "\n",
    "    if '.ipynb_checkpoints' in files:\n",
    "        files.remove('.ipynb_checkpoints')\n",
    "\n",
    "    X = []\n",
    "    labels = []\n",
    "    labellist = []\n",
    "\n",
    "    # Obtain labels and X\n",
    "    for filename in files:\n",
    "\n",
    "        name = os.path.join(video_dir, filename)\n",
    "        \n",
    "        for v_files in os.listdir(name):\n",
    "            \n",
    "            v_file_path = os.path.join(name, v_files)\n",
    "            label = filename\n",
    "            if label not in labellist:\n",
    "                if len(labellist) >= nb_classes:\n",
    "                    continue\n",
    "                labellist.append(label)\n",
    "            labels.append(label)\n",
    "            X.append(v_file_path)\n",
    "\n",
    "    if not os.path.isdir(result_dir):\n",
    "        os.makedir(result_dir)\n",
    "    with open(os.path.join(result_dir, 'classes.txt'), 'w') as fp:\n",
    "        for i in range(len(labellist)):\n",
    "            fp.write('{} {}\\n'.format(i, labellist[i]))\n",
    "\n",
    "    for num, label in enumerate(labellist):\n",
    "        for i in range(len(labels)):\n",
    "            if label == labels[i]:\n",
    "                labels[i] = num\n",
    "                \n",
    "    Y = np_utils.to_categorical(labels, nb_classes)\n",
    "\n",
    "    print('X_shape:{}\\tY_shape:{}'.format(len(X), Y.shape))\n",
    "\n",
    "    input_shape = (frames, img_rows, img_cols, channel)\n",
    "\n",
    "    return X, Y, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run models/slowfast.py\n",
    "import models.slowfast\n",
    "def resnet50(inputs, **kwargs):\n",
    "    model = SlowFast_body(inputs, [3, 4, 6, 3], bottleneck, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run models/i3dinception.py\n",
    "import models.i3dinception\n",
    "def I3DModel(model, nb_classes):\n",
    "\n",
    "    x = model.layers[-1].output\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = conv3d_bn(x, nb_classes, 1, 1, 1, padding='same', \n",
    "            use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n",
    "    num_frames_remaining = int(x.shape[1])\n",
    "    x = Reshape((num_frames_remaining, nb_classes))(x)\n",
    "    # logits (raw scores for each class)\n",
    "    x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "                output_shape=lambda s: (s[0], s[2]))(x)\n",
    "    x = Activation('softmax', name='prediction')(x)\n",
    "    model = Model(model.inputs, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class batchGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size, vid3d):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.vid3d = vid3d\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = []\n",
    "\n",
    "        for video in self.x[idx * self.batch_size:(idx + 1) * self.batch_size]:\n",
    "            batch_x.append(self.vid3d.video3d(video))\n",
    "\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_x = batch_x.astype('float32')\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_dir, result_dir, nb_classes = 101, batch_size = 32, epochs = 100, img_size = 224, frames = 25):\n",
    "\n",
    "    X, Y, input_shape = preprocess(video_dir, result_dir, nb_classes, img_size, \n",
    "                                   frames)\n",
    "\n",
    "    print(\"Input Shape = \", input_shape)\n",
    "\n",
    "    vid3d = Videoto3D(img_size, img_size, frames)\n",
    "\n",
    "    ## For i3D Inception model ##\n",
    "#     i3dmodel = Inception_Inflated3d(include_top=False,\n",
    "#                 weights='rgb_imagenet_and_kinetics',\n",
    "#                 input_tensor=None,\n",
    "#                 input_shape=input_shape,\n",
    "#                 dropout_prob=0.5,\n",
    "#                 endpoint_logit=False)\n",
    "    \n",
    "#     model = I3DModel(i3dmodel, nb_classes)\n",
    "    \n",
    "    ## For Slowfast model ##\n",
    "    x = Input(shape = input_shape)\n",
    "    model = resnet50(x, num_classes=nb_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "#     model = load_model('/content/drive/Shared drives/Drive 13/Dataset/Slowfast/slowfast-77-0.73.hd5')\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.15, shuffle = True)\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "        X_train, Y_train, test_size=0.15, shuffle = True)\n",
    "\n",
    "    print(\"X_train.shape = \", len(X_train))\n",
    "    print(\"X_val.shape = \", len(X_val))\n",
    "    print(\"X_test.shape = \", len(X_test))\n",
    "\n",
    "    # MODEL CHECK POINTS #\n",
    "\n",
    "    csv_logger = CSVLogger(\"/content/drive/Shared drives/Drive 13/Dataset/Slowfast/slowfast_model_history_log.csv\", append=True)\n",
    "\n",
    "    filepath=\"/content/drive/Shared drives/Drive 13/Dataset/Slowfast/slowfast-{epoch:02d}-{val_accuracy:.2f}.hd5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, mode='max')\n",
    "    callbacks_list = [checkpoint, csv_logger]\n",
    "\n",
    "    history = model.fit(batchGenerator(X_train, Y_train, batch_size, vid3d), steps_per_epoch = math.ceil(len(X_train) / batch_size), \n",
    "                                  validation_data = batchGenerator(X_val, Y_val, batch_size, vid3d), validation_steps = math.ceil(len(X_val) / batch_size), \n",
    "                                  epochs = epochs, verbose = 1, callbacks=callbacks_list, initial_epoch = 0)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    \n",
    "    if not os.path.isdir(result_dir):\n",
    "        os.makedir(result_dir)\n",
    "    with open(os.path.join(result_dir, 'slowfast.json'), 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    model.save_weights(os.path.join(result_dir, 'slowfast_finalweights.hd5'))\n",
    "\n",
    "    model.save(\"slowfast_finalmodel.hd5\")\n",
    "\n",
    "    loss, acc = model.evaluate(batchGenerator(X_test, Y_test, batch_size, vid3d),\n",
    "                               steps = math.ceil(len(X_test) / batch_size), verbose = 1)\n",
    "    \n",
    "    plot_history(history, result_dir)\n",
    "\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', acc)\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MODEL ##\n",
    "\n",
    "history, model = main(video_dir = 'DCSASS Dataset/', result_dir = 'output/', nb_classes = 14, batch_size = 8, epochs = 100, img_size = 224, frames = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_from_video(video_dir, nb_frames = 25, img_size = 224):\n",
    "\n",
    "    # Opens the Video file\n",
    "    cap = cv2.VideoCapture(video_dir)\n",
    "    i=0\n",
    "    frames = []\n",
    "    while(cap.isOpened() and i<nb_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (img_size, img_size))\n",
    "        frames.append(frame)\n",
    "        i+=1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return np.array(frames) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(video_dir, model, nb_frames = 25, img_size = 224):\n",
    "\n",
    "    X = frames_from_video(video_dir, nb_frames, img_size)\n",
    "    X = np.reshape(X, (1, nb_frames, img_size, img_size, 3))\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    preds = predictions.argmax(axis = 1)\n",
    "\n",
    "    classes = []\n",
    "    with open(os.path.join('output', 'classes.txt'), 'r') as fp:\n",
    "        for line in fp:\n",
    "            classes.append(line.split()[1])\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        print('Prediction - {} -- {}'.format(preds[i], classes[preds[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad marshal data (unknown type code)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## LOAD MODEL ##\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput/slowfast_finalmodel.hd5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m load_context\u001b[38;5;241m.\u001b[39mload_context(options):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    205\u001b[0m       (\u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile) \u001b[38;5;129;01mor\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mis_hdf5(filepath))):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m   filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, six\u001b[38;5;241m.\u001b[39mstring_types):\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py:183\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo model found in config file.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    182\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(model_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 183\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_config_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[1;32m    187\u001b[0m load_weights_from_hdf5_group(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m], model\u001b[38;5;241m.\u001b[39mlayers)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/saving/model_config.py:64\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`model_from_config` expects a dictionary, not a list. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     61\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaybe you meant to use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     62\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Sequential.from_config(config)`?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py:173\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    Layer instance (may be Model, Sequential, Network, Layer...)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m populate_deserializable_objects()\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:354\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[0;32m--> 354\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_GLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    358\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m CustomObjectScope(custom_objects):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(cls_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2261\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2256\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2258\u001b[0m   \u001b[38;5;66;03m# Since only FunctionalModel produces config, the model can only\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m   \u001b[38;5;66;03m# be constructed for FunctionalModel\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m-> 2261\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:668\u001b[0m, in \u001b[0;36mFunctional.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    654\u001b[0m   \u001b[38;5;124;03m\"\"\"Instantiates a Model from its config (output of `get_config()`).\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m  Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;124;03m      ValueError: In case of improperly formatted config dict.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 668\u001b[0m   input_tensors, output_tensors, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(inputs\u001b[38;5;241m=\u001b[39minput_tensors, outputs\u001b[38;5;241m=\u001b[39moutput_tensors,\n\u001b[1;32m    671\u001b[0m               name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    672\u001b[0m   connect_ancillary_layers(model, created_layers)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:1275\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m-> 1275\u001b[0m   \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:1257\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m   \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize \u001b[38;5;28;01mas\u001b[39;00m deserialize_layer  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m-> 1257\u001b[0m   layer \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m   created_layers[layer_name] \u001b[38;5;241m=\u001b[39m layer\n\u001b[1;32m   1260\u001b[0m node_count_by_layer[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(_should_skip_first_node(layer))\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py:173\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    Layer instance (may be Model, Sequential, Network, Layer...)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m populate_deserializable_objects()\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:354\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[0;32m--> 354\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_GLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    358\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m CustomObjectScope(custom_objects):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(cls_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py:1019\u001b[0m, in \u001b[0;36mLambda.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1018\u001b[0m   config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 1019\u001b[0m   function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_function_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodule\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfunction_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m   output_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_function_from_config(\n\u001b[1;32m   1023\u001b[0m       config, custom_objects, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_shape_module\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1024\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_shape_type\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1025\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py:1071\u001b[0m, in \u001b[0;36mLambda._parse_function_from_config\u001b[0;34m(cls, config, custom_objects, func_attr_name, module_attr_name, func_type_attr_name)\u001b[0m\n\u001b[1;32m   1065\u001b[0m   function \u001b[38;5;241m=\u001b[39m generic_utils\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m   1066\u001b[0m       config[func_attr_name],\n\u001b[1;32m   1067\u001b[0m       custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m   1068\u001b[0m       printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunction in Lambda layer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m function_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1070\u001b[0m   \u001b[38;5;66;03m# Unsafe deserialization from bytecode\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m   function \u001b[38;5;241m=\u001b[39m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc_attr_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m function_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1074\u001b[0m   function \u001b[38;5;241m=\u001b[39m config[func_attr_name]\n",
      "File \u001b[0;32m~/anaconda3/envs/env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:457\u001b[0m, in \u001b[0;36mfunc_load\u001b[0;34m(code, defaults, closure, globs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m, binascii\u001b[38;5;241m.\u001b[39mError):\n\u001b[1;32m    456\u001b[0m   raw_code \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_unicode_escape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 457\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43mmarshal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m globs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   globs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: bad marshal data (unknown type code)"
     ]
    }
   ],
   "source": [
    "## LOAD MODEL ##\n",
    "\n",
    "model = load_model('output/slowfast_finalmodel.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 224, 224, 3)\n",
      "Prediction - 1 -- Arrest\n"
     ]
    }
   ],
   "source": [
    "## MAKE PREDICTIONS ##\n",
    "\n",
    "predictions(video_dir = 'test/Arrest048_x264_21.mp4', model = model, nb_frames = 25, img_size = 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
